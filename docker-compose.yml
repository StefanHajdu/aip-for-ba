---
services:
  weaviate:
    command:
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --scheme
      - http
    container_name: weaviate-local
    image: cr.weaviate.io/semitechnologies/weaviate:1.26.4
    ports:
      - 8080:8080
      - 50051:50051
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: llama3
      OLLAMA_EMBED_MODEL: nomic-embed-text
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE: "text2vec-ollama"
      ENABLE_MODULES: "text2vec-ollama,generative-ollama"
      CLUSTER_HOSTNAME: "node1"
      ASYNC_INDEXING: "true"
  ollama:
    ports:
      - 11434:11434
    volumes:
      - /home/stephenx/LLMs/ollama:/root/.ollama
    environment:
      OLLAMA_MAX_LOADED_MODELS: 2
      OLLAMA_NUM_PARALLEL: 2
      OLLAMA_MAX_QUEUE: 10000
      OLLAMA_KEEP_ALIVE: -1
      OLLAMA_ORIGINS: "*"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    container_name: ollama-weaviate
    image: ollama/ollama:latest
volumes:
  weaviate_data:
  ollama:
